import os
from uuid import uuid4

import streamlit as st

# LangChain (0.2+ ê¶Œì¥)
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory

# -----------------------------
# ê¸°ë³¸ í™˜ê²½ ì„¸íŒ… / í‚¤ ë¡œë“œ
# -----------------------------
st.set_page_config(page_title="LangChain Multi-turn Chatbot", page_icon="ğŸ¤–", layout="centered")

if "openai" not in st.secrets or "api_key" not in st.secrets["openai"]:
    st.stop()  # ì•ˆì „í•˜ê²Œ ì¤‘ë‹¨
os.environ["OPENAI_API_KEY"] = st.secrets["openai"]["api_key"]

# -----------------------------
# UI ì‚¬ì´ë“œë°”
# -----------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    default_model = st.secrets["openai"].get("model", "gpt-4o-mini")
    model_name = st.selectbox("OpenAI ëª¨ë¸", [default_model, "gpt-4o-mini", "gpt-4.1", "gpt-5-mini-2025-08-07"], index=0)
    temperature = st.slider("ì°½ì˜ì„± (temperature)", 0.0, 1.2, 0.7, 0.1)
    sys_prompt = st.text_area(
        "System Prompt",
        value=(
            "ë‹¹ì‹ ì€ ì •í™•í•˜ê³  ì¹œì ˆí•œ í•œêµ­ì–´ AI ë¹„ì„œì…ë‹ˆë‹¤. "
            "ì‚¬ì‹¤ í™•ì¸ì„ ì¤‘ì‹œí•˜ë©°, ì½”ë“œ/ì˜ˆì‹œëŠ” ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ ê°„ê²°íˆ ì œì‹œí•˜ì„¸ìš”."
        ),
        height=120,
    )

    st.markdown("---")
    col_a, col_b = st.columns(2)
    with col_a:
        clear_btn = st.button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True)
    with col_b:
        new_sess_btn = st.button("ğŸ”„ ìƒˆ ì„¸ì…˜ ID", use_container_width=True)

    with st.container(border=True):
        st.write("ë¬¸ì˜/ê±´ì˜/í”¼ë“œë°± ì‚¬í•­ì´ ìˆë‹¤ë©´ ê°œë°œìì—ê²Œ ì•Œë ¤ì£¼ì„¸ìš”!\në°”ë¡œë°”ë¡œ ê³ ì¹˜ê±°ë‚˜ ì¶”ê°€í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤!")
        st.badge("scy0416@gmail.com", icon=":material/mail:", color="green")

# -----------------------------
# ì„¸ì…˜/íˆìŠ¤í† ë¦¬ ì €ì¥ìš© ìƒíƒœ
# -----------------------------
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid4())

if "stores" not in st.session_state:
    # ì—¬ëŸ¬ ì„¸ì…˜ì„ ë™ì‹œì— ê´€ë¦¬í•˜ê³  ì‹¶ì„ ìˆ˜ ìˆì–´ dictë¡œ ë³´ê´€
    st.session_state.stores = {}

def get_session_history(session_id: str) -> ChatMessageHistory:
    """LangChainì´ í˜¸ì¶œí•˜ëŠ” íˆìŠ¤í† ë¦¬ íŒ©í† ë¦¬ í•¨ìˆ˜"""
    store = st.session_state.stores
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# ë²„íŠ¼ ë™ì‘
if clear_btn:
    st.session_state.stores[st.session_state.session_id] = ChatMessageHistory()
if new_sess_btn:
    st.session_state.session_id = str(uuid4())

# -----------------------------
# LangChain êµ¬ì„±
# -----------------------------
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "{system_prompt}"),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}"),
    ]
)

llm = ChatOpenAI(
    model=model_name,
    temperature=temperature,
    streaming=True,  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
)

# í”„ë¡¬í”„íŠ¸ â†’ LLM íŒŒì´í”„ë¼ì¸
chain = prompt | llm

# ë©€í‹°í„´ íˆìŠ¤í† ë¦¬ ë˜í¼
conversational_chain = RunnableWithMessageHistory(
    chain,
    get_session_history,           # íˆìŠ¤í† ë¦¬ ê³µê¸‰ í•¨ìˆ˜
    input_messages_key="input",    # ì…ë ¥ í•„ë“œëª…
    history_messages_key="history" # íˆìŠ¤í† ë¦¬ placeholder í‚¤
    # output_messages_key ê¸°ë³¸ê°’ "output" (ChatModelì„ ì“°ë©´ ìë™ìœ¼ë¡œ AI ë©”ì‹œì§€ë¡œ ê¸°ë¡ë©ë‹ˆë‹¤)
)

# -----------------------------
# ìƒë‹¨ UI
# -----------------------------
st.title("ğŸ¤– LangChain ë©€í‹°í„´ ì±—ë´‡ (Streamlit + OpenAI)")
st.caption(f"ì„¸ì…˜ ID: `{st.session_state.session_id}`")

# ì§€ê¸ˆê¹Œì§€ì˜ íˆìŠ¤í† ë¦¬ ë³´ì—¬ì£¼ê¸° (ìƒˆë¡œê³ ì¹¨ ì‹œ ì¬ë Œë”)
history = get_session_history(st.session_state.session_id)
for msg in history.messages:
    role = "user" if msg.type == "human" else "assistant"
    with st.chat_message(role):
        st.markdown(msg.content)

# -----------------------------
# ì…ë ¥ & ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
# -----------------------------
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”â€¦")

def as_text_stream(chunks):
    """LangChainì˜ AIMessageChunk ìŠ¤íŠ¸ë¦¼ â†’ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³€í™˜"""
    for chunk in chunks:
        content = getattr(chunk, "content", None)
        if content:
            yield content

if user_input:
    # ë¨¼ì € ì‚¬ìš©ìì˜ ë§ í’ì„  í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(user_input)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ë§í’ì„ ì— ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
    with st.chat_message("assistant"):
        cfg = {"configurable": {"session_id": st.session_state.session_id}}
        stream = conversational_chain.stream(
            {"system_prompt": sys_prompt, "input": user_input},
            config=cfg,
        )
        st.write_stream(as_text_stream(stream))

    # ìŠ¤íŠ¸ë¦¬ë°ì´ ëë‚˜ë©´ LangChainì´ ìë™ìœ¼ë¡œ íˆìŠ¤í† ë¦¬ì—
    # (human â†’ ai) ìŒì„ ê¸°ë¡í•©ë‹ˆë‹¤. Streamlitì€ ë‹¤ìŒ rerun ë•Œ ìœ„ì—ì„œ ë‹¤ì‹œ ê·¸ë ¤ìš”.
